{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a5406f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic funtion\n",
    "import cv2 as cv\n",
    "\n",
    "# Read in an image\n",
    "img = cv.imread('../Resources/Photos/park.jpg')\n",
    "cv.imshow('Park', img)\n",
    "\n",
    "# Converting to grayscale\n",
    "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "cv.imshow('Gray', gray)\n",
    "\n",
    "# Blur \n",
    "blur = cv.GaussianBlur(img, (7,7), cv.BORDER_DEFAULT)\n",
    "cv.imshow('Blur', blur)\n",
    "\n",
    "# Edge Cascade\n",
    "canny = cv.Canny(blur, 125, 175)\n",
    "cv.imshow('Canny Edges', canny)\n",
    "\n",
    "# Dilating the image\n",
    "dilated = cv.dilate(canny, (7,7), iterations=3)\n",
    "cv.imshow('Dilated', dilated)\n",
    "\n",
    "# Eroding\n",
    "eroded = cv.erode(dilated, (7,7), iterations=3)\n",
    "cv.imshow('Eroded', eroded)\n",
    "\n",
    "# Resize\n",
    "resized = cv.resize(img, (500,500), interpolation=cv.INTER_CUBIC)\n",
    "cv.imshow('Resized', resized)\n",
    "\n",
    "# Cropping\n",
    "cropped = img[50:200, 200:400]\n",
    "cv.imshow('Cropped', cropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bf7561",
   "metadata": {},
   "outputs": [],
   "source": [
    "#contour \n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "img = cv.imread('../Resources/Photos/cats.jpg')\n",
    "cv.imshow('Cats', img)\n",
    "\n",
    "blank = np.zeros(img.shape, dtype='uint8')\n",
    "cv.imshow('Blank', blank)\n",
    "\n",
    "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "cv.imshow('Gray', gray)\n",
    "\n",
    "blur = cv.GaussianBlur(gray, (5,5), cv.BORDER_DEFAULT)\n",
    "cv.imshow('Blur', blur)\n",
    "\n",
    "canny = cv.Canny(blur, 125, 175)\n",
    "cv.imshow('Canny Edges', canny)\n",
    "\n",
    "# ret, thresh = cv.threshold(gray, 125, 255, cv.THRESH_BINARY)\n",
    "# cv.imshow('Thresh', thresh)\n",
    "\n",
    "contours, hierarchies = cv.findContours(canny, cv.RETR_LIST, cv.CHAIN_APPROX_SIMPLE)\n",
    "print(f'{len(contours)} contour(s) found!')\n",
    "\n",
    "cv.drawContours(blank, contours, -1, (0,0,255), 1)\n",
    "cv.imshow('Contours Drawn', blank)\n",
    "\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd622af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#draw\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "blank = np.zeros((500,500,3), dtype='uint8')\n",
    "cv.imshow('Blank', blank)\n",
    "\n",
    "# 1. Paint the image a certain colour\n",
    "blank[200:300, 300:400] = 0,0,255\n",
    "cv.imshow('Green', blank)\n",
    "\n",
    "# 2. Draw a Rectangle\n",
    "cv.rectangle(blank, (0,0), (blank.shape[1]//2, blank.shape[0]//2), (0,255,0), thickness=-1)\n",
    "cv.imshow('Rectangle', blank)\n",
    "\n",
    "# 3. Draw A circle\n",
    "cv.circle(blank, (blank.shape[1]//2, blank.shape[0]//2), 40, (0,0,255), thickness=-1)\n",
    "cv.imshow('Circle', blank)\n",
    "\n",
    "# 4. Draw a line\n",
    "cv.line(blank, (100,250), (300,400), (255,255,255), thickness=3)\n",
    "cv.imshow('Line', blank)\n",
    "\n",
    "# 5. Write text\n",
    "cv.putText(blank, 'Hello, my name is Jason!!!', (0,225), cv.FONT_HERSHEY_TRIPLEX, 1.0, (0,255,0), 2)\n",
    "cv.imshow('Text', blank)\n",
    "\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57095546",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pylint:disable=no-member\n",
    "#read\n",
    "import cv2 as cv\n",
    "\n",
    "img = cv.imread('../Resources/Photos/cats.jpg')\n",
    "cv.imshow('Cats', img)\n",
    "\n",
    "cv.waitKey(0)\n",
    "\n",
    "# Reading Videos\n",
    "capture = cv.VideoCapture('../Resources/Videos/dog.mp4')\n",
    "\n",
    "while True:\n",
    "    isTrue, frame = capture.read()\n",
    "    \n",
    "    # if cv.waitKey(20) & 0xFF==ord('d'):\n",
    "    # This is the preferred way - if `isTrue` is false (the frame could \n",
    "    # not be read, or we're at the end of the video), we immediately\n",
    "    # break from the loop. \n",
    "    if isTrue:    \n",
    "        cv.imshow('Video', frame)\n",
    "        if cv.waitKey(20) & 0xFF==ord('d'):\n",
    "            break            \n",
    "    else:\n",
    "        break\n",
    "\n",
    "capture.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f893119e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#thresh\n",
    "import cv2 as cv\n",
    "\n",
    "img = cv.imread('../Resources/Photos/cats.jpg')\n",
    "cv.imshow('Cats', img)\n",
    "\n",
    "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "cv.imshow('Gray', gray)\n",
    "\n",
    "# Simple Thresholding\n",
    "threshold, thresh = cv.threshold(gray, 150, 255, cv.THRESH_BINARY )\n",
    "cv.imshow('Simple Thresholded', thresh)\n",
    "\n",
    "threshold, thresh_inv = cv.threshold(gray, 150, 255, cv.THRESH_BINARY_INV )\n",
    "cv.imshow('Simple Thresholded Inverse', thresh_inv)\n",
    "\n",
    "# Adaptive Thresholding\n",
    "adaptive_thresh = cv.adaptiveThreshold(gray, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY_INV, 11, 9)\n",
    "cv.imshow('Adaptive Thresholding', adaptive_thresh)\n",
    "\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90194b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformation\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "img = cv.imread('../Resources/Photos/park.jpg')\n",
    "cv.imshow('Park', img)\n",
    "\n",
    "# Translation\n",
    "def translate(img, x, y):\n",
    "    transMat = np.float32([[1,0,x],[0,1,y]])\n",
    "    dimensions = (img.shape[1], img.shape[0])\n",
    "    return cv.warpAffine(img, transMat, dimensions)\n",
    "\n",
    "# -x --> Left\n",
    "# -y --> Up\n",
    "# x --> Right\n",
    "# y --> Down\n",
    "\n",
    "translated = translate(img, -100, 100)\n",
    "cv.imshow('Translated', translated)\n",
    "\n",
    "# Rotation\n",
    "def rotate(img, angle, rotPoint=None):\n",
    "    (height,width) = img.shape[:2]\n",
    "\n",
    "    if rotPoint is None:\n",
    "        rotPoint = (width//2,height//2)\n",
    "    \n",
    "    rotMat = cv.getRotationMatrix2D(rotPoint, angle, 1.0)\n",
    "    dimensions = (width,height)\n",
    "\n",
    "    return cv.warpAffine(img, rotMat, dimensions)\n",
    "\n",
    "rotated = rotate(img, -45)\n",
    "cv.imshow('Rotated', rotated)\n",
    "\n",
    "rotated_rotated = rotate(img, -90)\n",
    "cv.imshow('Rotated Rotated', rotated_rotated)\n",
    "\n",
    "# Resizing\n",
    "resized = cv.resize(img, (500,500), interpolation=cv.INTER_CUBIC)\n",
    "cv.imshow('Resized', resized)\n",
    "\n",
    "# Flipping\n",
    "flip = cv.flip(img, -1)\n",
    "cv.imshow('Flip', flip)\n",
    "\n",
    "# Cropping\n",
    "cropped = img[200:400, 300:400]\n",
    "cv.imshow('Cropped', cropped)\n",
    "\n",
    "\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd49ccaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bitwise\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "blank = np.zeros((400,400), dtype='uint8')\n",
    "\n",
    "rectangle = cv.rectangle(blank.copy(), (30,30), (370,370), 255, -1)\n",
    "circle = cv.circle(blank.copy(), (200,200), 200, 255, -1)\n",
    "\n",
    "cv.imshow('Rectangle', rectangle)\n",
    "cv.imshow('Circle', circle)\n",
    "\n",
    "# bitwise AND --> intersecting regions\n",
    "bitwise_and = cv.bitwise_and(rectangle, circle)\n",
    "cv.imshow('Bitwise AND', bitwise_and)\n",
    "\n",
    "# bitwise OR --> non-intersecting and intersecting regions\n",
    "bitwise_or = cv.bitwise_or(rectangle, circle)\n",
    "cv.imshow('Bitwise OR', bitwise_or)\n",
    "\n",
    "# bitwise XOR --> non-intersecting regions\n",
    "bitwise_xor = cv.bitwise_xor(rectangle, circle)\n",
    "cv.imshow('Bitwise XOR', bitwise_xor)\n",
    "\n",
    "# bitwise NOT\n",
    "bitwise_not = cv.bitwise_not(circle)\n",
    "cv.imshow('Circle NOT', bitwise_not)\n",
    "\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da122cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#blurring\n",
    "import cv2 as cv\n",
    "\n",
    "img = cv.imread('../Resources/Photos/cats.jpg')\n",
    "cv.imshow('Cats', img)\n",
    "\n",
    "# Averaging\n",
    "average = cv.blur(img, (3,3))\n",
    "cv.imshow('Average Blur', average)\n",
    "\n",
    "# Gaussian Blur\n",
    "gauss = cv.GaussianBlur(img, (3,3), 0)\n",
    "cv.imshow('Gaussian Blur', gauss)\n",
    "\n",
    "# Median Blur\n",
    "median = cv.medianBlur(img, 3)\n",
    "cv.imshow('Median Blur', median)\n",
    "\n",
    "# Bilateral\n",
    "bilateral = cv.bilateralFilter(img, 10, 35, 25)\n",
    "cv.imshow('Bilateral', bilateral)\n",
    "\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434fc4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#colour_space\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = cv.imread('../Resources/Photos/park.jpg')\n",
    "cv.imshow('Park', img)\n",
    "\n",
    "# plt.imshow(img)\n",
    "# plt.show()\n",
    "\n",
    "# BGR to Grayscale\n",
    "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "cv.imshow('Gray', gray)\n",
    "\n",
    "# BGR to HSV\n",
    "hsv = cv.cvtColor(img, cv.COLOR_BGR2HSV)\n",
    "cv.imshow('HSV', hsv)\n",
    "\n",
    "# BGR to L*a*b\n",
    "lab = cv.cvtColor(img, cv.COLOR_BGR2LAB)\n",
    "cv.imshow('LAB', lab)\n",
    "\n",
    "# BGR to RGB\n",
    "rgb = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "cv.imshow('RGB', rgb)\n",
    "\n",
    "# HSV to BGR\n",
    "lab_bgr = cv.cvtColor(lab, cv.COLOR_LAB2BGR)\n",
    "cv.imshow('LAB --> BGR', lab_bgr)\n",
    "\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1ad113",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gradient\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "img = cv.imread('../Resources/Photos/park.jpg')\n",
    "cv.imshow('Park', img)\n",
    "\n",
    "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "cv.imshow('Gray', gray)\n",
    "\n",
    "# Laplacian\n",
    "lap = cv.Laplacian(gray, cv.CV_64F)\n",
    "lap = np.uint8(np.absolute(lap))\n",
    "cv.imshow('Laplacian', lap)\n",
    "\n",
    "# Sobel \n",
    "sobelx = cv.Sobel(gray, cv.CV_64F, 1, 0)\n",
    "sobely = cv.Sobel(gray, cv.CV_64F, 0, 1)\n",
    "combined_sobel = cv.bitwise_or(sobelx, sobely)\n",
    "\n",
    "cv.imshow('Sobel X', sobelx)\n",
    "cv.imshow('Sobel Y', sobely)\n",
    "cv.imshow('Combined Sobel', combined_sobel)\n",
    "\n",
    "canny = cv.Canny(gray, 150, 175)\n",
    "cv.imshow('Canny', canny)\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fda22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#histogram\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "img = cv.imread('../Resources/Photos/cats.jpg')\n",
    "cv.imshow('Cats', img)\n",
    "\n",
    "blank = np.zeros(img.shape[:2], dtype='uint8')\n",
    "\n",
    "# gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "# cv.imshow('Gray', gray)\n",
    "\n",
    "mask = cv.circle(blank, (img.shape[1]//2,img.shape[0]//2), 100, 255, -1)\n",
    "\n",
    "masked = cv.bitwise_and(img,img,mask=mask)\n",
    "cv.imshow('Mask', masked)\n",
    "\n",
    "# GRayscale histogram\n",
    "# gray_hist = cv.calcHist([gray], [0], mask, [256], [0,256] )\n",
    "\n",
    "# plt.figure()\n",
    "# plt.title('Grayscale Histogram')\n",
    "# plt.xlabel('Bins')\n",
    "# plt.ylabel('# of pixels')\n",
    "# plt.plot(gray_hist)\n",
    "# plt.xlim([0,256])\n",
    "# plt.show()\n",
    "\n",
    "# Colour Histogram\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Colour Histogram')\n",
    "plt.xlabel('Bins')\n",
    "plt.ylabel('# of pixels')\n",
    "colors = ('b', 'g', 'r')\n",
    "for i,col in enumerate(colors):\n",
    "    hist = cv.calcHist([img], [i], mask, [256], [0,256])\n",
    "    plt.plot(hist, color=col)\n",
    "    plt.xlim([0,256])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36496aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#masking\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "img = cv.imread('../Resources/Photos/cats 2.jpg')\n",
    "cv.imshow('Cats', img)\n",
    "\n",
    "blank = np.zeros(img.shape[:2], dtype='uint8')\n",
    "cv.imshow('Blank Image', blank)\n",
    "\n",
    "circle = cv.circle(blank.copy(), (img.shape[1]//2 + 45,img.shape[0]//2), 100, 255, -1)\n",
    "\n",
    "rectangle = cv.rectangle(blank.copy(), (30,30), (370,370), 255, -1)\n",
    "\n",
    "weird_shape = cv.bitwise_and(circle,rectangle)\n",
    "cv.imshow('Weird Shape', weird_shape)\n",
    "\n",
    "masked = cv.bitwise_and(img,img,mask=weird_shape)\n",
    "cv.imshow('Weird Shaped Masked Image', masked)\n",
    "\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91aa3ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rescale_resize\n",
    "import cv2 as cv\n",
    "\n",
    "# img = cv.imread('../Resources/Photos/cat.jpg')\n",
    "# cv.imshow('Cat', img)\n",
    "\n",
    "def rescaleFrame(frame, scale=0.75):\n",
    "    # Images, Videos and Live Video\n",
    "    width = int(frame.shape[1] * scale)\n",
    "    height = int(frame.shape[0] * scale)\n",
    "\n",
    "    dimensions = (width,height)\n",
    "\n",
    "    return cv.resize(frame, dimensions, interpolation=cv.INTER_AREA)\n",
    "\n",
    "def changeRes(width,height):\n",
    "    # Live video\n",
    "    capture.set(3,width)\n",
    "    capture.set(4,height)\n",
    "    \n",
    "# Reading Videos\n",
    "capture = cv.VideoCapture('../Resources/Videos/dog.mp4')\n",
    "\n",
    "while True:\n",
    "    isTrue, frame = capture.read()\n",
    "\n",
    "    frame_resized = rescaleFrame(frame, scale=.2)\n",
    "    \n",
    "    cv.imshow('Video', frame)\n",
    "    cv.imshow('Video Resized', frame_resized)\n",
    "\n",
    "    if cv.waitKey(20) & 0xFF==ord('d'):\n",
    "        break\n",
    "\n",
    "capture.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a11dda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spiltmerge\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "img = cv.imread('../Resources/Photos/park.jpg')\n",
    "cv.imshow('Park', img)\n",
    "\n",
    "blank = np.zeros(img.shape[:2], dtype='uint8')\n",
    "\n",
    "b,g,r = cv.split(img)\n",
    "\n",
    "blue = cv.merge([b,blank,blank])\n",
    "green = cv.merge([blank,g,blank])\n",
    "red = cv.merge([blank,blank,r])\n",
    "\n",
    "\n",
    "cv.imshow('Blue', blue)\n",
    "cv.imshow('Green', green)\n",
    "cv.imshow('Red', red)\n",
    "\n",
    "print(img.shape)\n",
    "print(b.shape)\n",
    "print(g.shape)\n",
    "print(r.shape)\n",
    "\n",
    "merged = cv.merge([b,g,r])\n",
    "cv.imshow('Merged Image', merged)\n",
    "\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42844cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#face_detection\n",
    "import cv2 as cv\n",
    "\n",
    "img = cv.imread('../Resources/Photos/group 1.jpg')\n",
    "cv.imshow('Group of 5 people', img)\n",
    "\n",
    "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "cv.imshow('Gray People', gray)\n",
    "\n",
    "haar_cascade = cv.CascadeClassifier('haar_face.xml')\n",
    "\n",
    "faces_rect = haar_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=1)\n",
    "\n",
    "print(f'Number of faces found = {len(faces_rect)}')\n",
    "\n",
    "for (x,y,w,h) in faces_rect:\n",
    "    cv.rectangle(img, (x,y), (x+w,y+h), (0,255,0), thickness=2)\n",
    "\n",
    "cv.imshow('Detected Faces', img)\n",
    "\n",
    "\n",
    "\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1cd88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#facerecognition\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "\n",
    "haar_cascade = cv.CascadeClassifier('haar_face.xml')\n",
    "\n",
    "people = ['Ben Afflek', 'Elton John', 'Jerry Seinfield', 'Madonna', 'Mindy Kaling']\n",
    "# features = np.load('features.npy', allow_pickle=True)\n",
    "# labels = np.load('labels.npy')\n",
    "\n",
    "face_recognizer = cv.face.LBPHFaceRecognizer_create()\n",
    "face_recognizer.read('face_trained.yml')\n",
    "\n",
    "img = cv.imread(r'../Resources\\Faces\\val\\elton_john/1.jpg')\n",
    "\n",
    "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "cv.imshow('Person', gray)\n",
    "\n",
    "# Detect the face in the image\n",
    "faces_rect = haar_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "\n",
    "for (x,y,w,h) in faces_rect:\n",
    "    faces_roi = gray[y:y+h,x:x+w]\n",
    "\n",
    "    label, confidence = face_recognizer.predict(faces_roi)\n",
    "    print(f'Label = {people[label]} with a confidence of {confidence}')\n",
    "\n",
    "    cv.putText(img, str(people[label]), (20,20), cv.FONT_HERSHEY_COMPLEX, 1.0, (0,255,0), thickness=2)\n",
    "    cv.rectangle(img, (x,y), (x+w,y+h), (0,255,0), thickness=2)\n",
    "\n",
    "cv.imshow('Detected Face', img)\n",
    "\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d46bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#facetrain\n",
    "\n",
    "import os\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "people = ['Ben Afflek', 'Elton John', 'Jerry Seinfield', 'Madonna', 'Mindy Kaling']\n",
    "DIR = r'..Media Files\\Faces\\train'\n",
    "\n",
    "haar_cascade = cv.CascadeClassifier('haar_face.xml')\n",
    "\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "def create_train():\n",
    "    for person in people:\n",
    "        path = os.path.join(DIR, person)\n",
    "        label = people.index(person)\n",
    "\n",
    "        for img in os.listdir(path):\n",
    "            img_path = os.path.join(path,img)\n",
    "\n",
    "            img_array = cv.imread(img_path)\n",
    "            if img_array is None:\n",
    "                continue \n",
    "                \n",
    "            gray = cv.cvtColor(img_array, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "            faces_rect = haar_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=4)\n",
    "\n",
    "            for (x,y,w,h) in faces_rect:\n",
    "                faces_roi = gray[y:y+h, x:x+w]\n",
    "                features.append(faces_roi)\n",
    "                labels.append(label)\n",
    "\n",
    "create_train()\n",
    "print('Training done ---------------')\n",
    "\n",
    "features = np.array(features, dtype='object')\n",
    "labels = np.array(labels)\n",
    "\n",
    "face_recognizer = cv.face.LBPHFaceRecognizer_create()\n",
    "\n",
    "# Train the Recognizer on the features list and the labels list\n",
    "face_recognizer.train(features,labels)\n",
    "\n",
    "face_recognizer.save('face_trained.yml')\n",
    "np.save('features.npy', features)\n",
    "np.save('labels.npy', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd62429",
   "metadata": {},
   "outputs": [],
   "source": [
    "#simpson\n",
    "# Installing `caer` and `canaro` since they don't come pre-installed\n",
    "# Uncomment the following line:\n",
    "# !pip install --upgrade caer canaro\n",
    "\n",
    "import os\n",
    "import caer\n",
    "import canaro\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "\n",
    "IMG_SIZE = (80,80)\n",
    "channels = 1\n",
    "char_path = r'../input/the-simpsons-characters-dataset/simpsons_dataset'\n",
    "\n",
    "# Creating a character dictionary, sorting it in descending order\n",
    "char_dict = {}\n",
    "for char in os.listdir(char_path):\n",
    "    char_dict[char] = len(os.listdir(os.path.join(char_path,char)))\n",
    "\n",
    "# Sort in descending order\n",
    "char_dict = caer.sort_dict(char_dict, descending=True)\n",
    "char_dict\n",
    "\n",
    "#  Getting the first 10 categories with the most number of images\n",
    "characters = []\n",
    "count = 0\n",
    "for i in char_dict:\n",
    "    characters.append(i[0])\n",
    "    count += 1\n",
    "    if count >= 10:\n",
    "        break\n",
    "characters\n",
    "\n",
    "# Create the training data\n",
    "train = caer.preprocess_from_dir(char_path, characters, channels=channels, IMG_SIZE=IMG_SIZE, isShuffle=True)\n",
    "\n",
    "# Number of training samples\n",
    "len(train)\n",
    "\n",
    "# Visualizing the data (OpenCV doesn't display well in Jupyter notebooks)\n",
    "plt.figure(figsize=(30,30))\n",
    "plt.imshow(train[0][0], cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "# Separating the array and corresponding labels\n",
    "featureSet, labels = caer.sep_train(train, IMG_SIZE=IMG_SIZE)\n",
    "\n",
    "\n",
    "# Normalize the featureSet ==> (0,1)\n",
    "featureSet = caer.normalize(featureSet)\n",
    "# Converting numerical labels to binary class vectors\n",
    "labels = to_categorical(labels, len(characters))\n",
    "\n",
    "\n",
    "# Creating train and validation data\n",
    "x_train, x_val, y_train, y_val = caer.train_test_split(featureSet, labels, val_ratio=.2)\n",
    "\n",
    "# Deleting variables to save memory\n",
    "del train\n",
    "del featureSet\n",
    "del labels \n",
    "gc.collect()\n",
    "\n",
    "# Useful variables when training\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "\n",
    "# Image data generator (introduces randomness in network ==> better accuracy)\n",
    "datagen = canaro.generators.imageDataGenerator()\n",
    "train_gen = datagen.flow(x_train, y_train, batch_size=BATCH_SIZE)\n",
    "\n",
    "# Create our model (returns the compiled model)\n",
    "model = canaro.models.createSimpsonsModel(IMG_SIZE=IMG_SIZE, channels=channels, output_dim=len(characters), \n",
    "                                         loss='binary_crossentropy', decay=1e-7, learning_rate=0.001, momentum=0.9,\n",
    "                                         nesterov=True)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Training the model\n",
    "\n",
    "callbacks_list = [LearningRateScheduler(canaro.lr_schedule)]\n",
    "training = model.fit(train_gen,\n",
    "                    steps_per_epoch=len(x_train)//BATCH_SIZE,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=(x_val,y_val),\n",
    "                    validation_steps=len(y_val)//BATCH_SIZE,\n",
    "                    callbacks = callbacks_list)\n",
    "\n",
    "print(characters)\n",
    "\n",
    "\n",
    "\"\"\"## Testing\"\"\"\n",
    "\n",
    "test_path = r'../input/the-simpsons-characters-dataset/kaggle_simpson_testset/kaggle_simpson_testset/charles_montgomery_burns_0.jpg'\n",
    "\n",
    "img = cv.imread(test_path)\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "def prepare(image):\n",
    "    image = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "    image = cv.resize(image, IMG_SIZE)\n",
    "    image = caer.reshape(image, IMG_SIZE, 1)\n",
    "    return image\n",
    "\n",
    "predictions = model.predict(prepare(img))\n",
    "\n",
    "# Getting class with the highest probability\n",
    "print(characters[np.argmax(predictions[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f281a0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763fccb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb7b96c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6913e4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9c783a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b236e42a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
